{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHcTRGvUmoME"
      },
      "source": [
        "# Dance Diffusion finetune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u97w34BXmust"
      },
      "source": [
        "Licensed under the MIT License\n",
        "\n",
        "Copyright (c) 2022 Zach Evans\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in\n",
        "all copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
        "THE SOFTWARE.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU97ZiP7nSKS"
      },
      "source": [
        "# Set Up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "mxb-qgh0nUOf"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[WinError 2] The system cannot find the file specified",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [1], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m simple_nvidia_smi_display \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\u001b[38;5;66;03m#@param {type:\"boolean\"}\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m simple_nvidia_smi_display:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#!nvidia-smi\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m     nvidiasmi_output \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnvidia-smi\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-L\u001b[39m\u001b[38;5;124m'\u001b[39m], stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE)\u001b[38;5;241m.\u001b[39mstdout\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(nvidiasmi_output)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#!nvidia-smi -i 0 -e 0\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jschmiemann\\Anaconda3\\envs\\jupy\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    502\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstdout\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[0;32m    503\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mstderr\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m PIPE\n\u001b[1;32m--> 505\u001b[0m \u001b[39mwith\u001b[39;00m Popen(\u001b[39m*\u001b[39mpopenargs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mas\u001b[39;00m process:\n\u001b[0;32m    506\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    507\u001b[0m         stdout, stderr \u001b[39m=\u001b[39m process\u001b[39m.\u001b[39mcommunicate(\u001b[39minput\u001b[39m, timeout\u001b[39m=\u001b[39mtimeout)\n",
            "File \u001b[1;32mc:\\Users\\jschmiemann\\Anaconda3\\envs\\jupy\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    947\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext_mode:\n\u001b[0;32m    948\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mTextIOWrapper(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[39m=\u001b[39mencoding, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m    952\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m    953\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m    954\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m    955\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m    956\u001b[0m                         errread, errwrite,\n\u001b[0;32m    957\u001b[0m                         restore_signals,\n\u001b[0;32m    958\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m    959\u001b[0m                         start_new_session)\n\u001b[0;32m    960\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[39m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m    962\u001b[0m     \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mfilter\u001b[39m(\u001b[39mNone\u001b[39;00m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdin, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstdout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstderr)):\n",
            "File \u001b[1;32mc:\\Users\\jschmiemann\\Anaconda3\\envs\\jupy\\lib\\subprocess.py:1420\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[39m# Start the process\u001b[39;00m\n\u001b[0;32m   1419\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1420\u001b[0m     hp, ht, pid, tid \u001b[39m=\u001b[39m _winapi\u001b[39m.\u001b[39;49mCreateProcess(executable, args,\n\u001b[0;32m   1421\u001b[0m                              \u001b[39m# no special security\u001b[39;49;00m\n\u001b[0;32m   1422\u001b[0m                              \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m   1423\u001b[0m                              \u001b[39mint\u001b[39;49m(\u001b[39mnot\u001b[39;49;00m close_fds),\n\u001b[0;32m   1424\u001b[0m                              creationflags,\n\u001b[0;32m   1425\u001b[0m                              env,\n\u001b[0;32m   1426\u001b[0m                              cwd,\n\u001b[0;32m   1427\u001b[0m                              startupinfo)\n\u001b[0;32m   1428\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m     \u001b[39m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m     \u001b[39m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[39m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m     \u001b[39m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1435\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1436\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1437\u001b[0m                          errread, errwrite)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
          ]
        }
      ],
      "source": [
        "#@title Check GPU Status\n",
        "import subprocess\n",
        "simple_nvidia_smi_display = True#@param {type:\"boolean\"}\n",
        "if simple_nvidia_smi_display:\n",
        "    #!nvidia-smi\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "else:\n",
        "    #!nvidia-smi -i 0 -e 0\n",
        "    nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_output)\n",
        "    nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(nvidiasmi_ecc_note)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "T_mFtzHvnlJL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google Colab not detected.\n"
          ]
        }
      ],
      "source": [
        "#@title Prepare folders\n",
        "import subprocess, os, sys, ipykernel\n",
        "\n",
        "def gitclone(url, targetdir=None):\n",
        "    if targetdir:\n",
        "        res = subprocess.run(['git', 'clone', url, targetdir], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    else:\n",
        "        res = subprocess.run(['git', 'clone', url], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipi(modulestr):\n",
        "    res = subprocess.run(['pip', 'install', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def pipie(modulestr):\n",
        "    res = subprocess.run(['git', 'install', '-e', modulestr], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "def wget(url, outputdir):\n",
        "    res = subprocess.run(['wget', url, '-P', f'{outputdir}'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "    print(res)\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab detected. Using Google Drive.\")\n",
        "    is_colab = True\n",
        "    google_drive = True #@param {type:\"boolean\"}\n",
        "    #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
        "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "except:\n",
        "    is_colab = False\n",
        "    google_drive = False\n",
        "    save_models_to_google_drive = False\n",
        "    print(\"Google Colab not detected.\")\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive is True:\n",
        "        drive._mount('/content/drive')\n",
        "        root_path = '/content/drive/MyDrive/AI/Bass_Diffusion'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "else:\n",
        "    root_path = os.getcwd()\n",
        "\n",
        "import os\n",
        "def createPath(filepath):\n",
        "    os.makedirs(filepath, exist_ok=True)\n",
        "\n",
        "initDirPath = f'{root_path}/init_audio'\n",
        "createPath(initDirPath)\n",
        "outDirPath = f'{root_path}/audio_out'\n",
        "createPath(outDirPath)\n",
        "\n",
        "if is_colab:\n",
        "    if google_drive and not save_models_to_google_drive or not google_drive:\n",
        "        model_path = '/content/models'\n",
        "        createPath(model_path)\n",
        "    if google_drive and save_models_to_google_drive:\n",
        "        model_path = f'{root_path}/models'\n",
        "        createPath(model_path)\n",
        "else:\n",
        "    model_path = f'{root_path}/models'\n",
        "    createPath(model_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "y9BS0ks1oEgP"
      },
      "outputs": [],
      "source": [
        "#@title Install dependencies\n",
        "!git clone https://github.com/harmonai-org/sample-generator\n",
        "!pip install /content/sample-generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xq2TJzIPTcJ"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "oxJFFEZ8CD8g"
      },
      "outputs": [],
      "source": [
        "#@markdown Log in to [Weights & Biases](https://wandb.ai/) for run tracking\n",
        "!wandb login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-Q0XrS0HEmch"
      },
      "outputs": [],
      "source": [
        "#@markdown Name for the finetune project, used as the W&B project name, as well as the directory for the saved checkpoints\n",
        "NAME=\"dd-drums-finetune\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the directory of audio data to use for fine-tuning\n",
        "TRAINING_DIR=\"/content/drive/MyDrive/Audio/Drums\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Path to the checkpoint to fine-tune\n",
        "CKPT_PATH=\"/content/drive/MyDrive/AI/models/jmann-small-190k.ckpt\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Directory path for saving the fine-tuned outputs\n",
        "OUTPUT_DIR=\"/content/drive/MyDrive/AI/models/DanceDiffusion/finetune\" #@param {type:\"string\"}\n",
        "\n",
        "#@markdown Number of training steps between demos\n",
        "DEMO_EVERY=250 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of training steps between saving model checkpoints\n",
        "CHECKPOINT_EVERY=500 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Sample rate to train at\n",
        "SAMPLE_RATE=48000 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Number of audio samples per training sample\n",
        "SAMPLE_SIZE=65536 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown If true, the audio samples provided will be randomly cropped to SAMPLE_SIZE samples\n",
        "#@markdown\n",
        "#@markdown Turn off if you want to ensure the training data always starts at the beginning of the audio files (good for things like drum one-shots)\n",
        "RANDOM_CROP=True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown Batch size to fine-tune (make it as high as it can go for your GPU)\n",
        "BATCH_SIZE=2 #@param {type:\"number\"}\n",
        "\n",
        "#@markdown Accumulate gradients over n batches, useful for training on one GPU. \n",
        "#@markdown\n",
        "#@markdown Effective batch size is BATCH_SIZE * ACCUM_BATCHES.\n",
        "#@markdown\n",
        "#@markdown Also increases the time between demos and saved checkpoints\n",
        "ACCUM_BATCHES=4 #@param {type:\"number\"}\n",
        "\n",
        "random_crop_str = f\"--random-crop True\" if RANDOM_CROP else \"\"\n",
        "\n",
        "# Escape spaces in paths\n",
        "CKPT_PATH = CKPT_PATH.replace(f\" \", f\"\\ \")\n",
        "OUTPUT_DIR = f\"{OUTPUT_DIR}/{NAME}\".replace(f\" \", f\"\\ \")\n",
        "\n",
        "%cd /content/sample-generator/\n",
        "\n",
        "!python3 /content/sample-generator/train_uncond.py --ckpt-path $CKPT_PATH --name $NAME --training-dir $TRAINING_DIR --sample-size $SAMPLE_SIZE --sample-rate $SAMPLE_RATE --batch-size $BATCH_SIZE --demo-every $DEMO_EVERY --demo-steps 100 --checkpoint-every $CHECKPOINT_EVERY --num-workers 2 $random_crop_str --save-path $OUTPUT_DIR"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "HHcTRGvUmoME"
      ],
      "name": "Finetune Dance Diffusion.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "26aa446eedf39aa0738f428b770f6ee8187dad49d2f07b4ae22869be1e0be59b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
